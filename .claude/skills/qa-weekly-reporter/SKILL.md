---
name: QA Weekly Reporter
description: Generate comprehensive weekly QA reports from test execution data, issue tracking, and automation metrics. Use when the user asks to create a weekly report, mentions "ì£¼ê°„ ë¦¬í¬íŠ¸", "weekly report", "QA ë¦¬í¬íŠ¸", or when it's Friday afternoon and reporting is needed.
---

# QA Weekly Reporter

## Purpose

This skill automatically generates structured weekly QA reports that summarize testing activities, quality metrics, and actionable insights for stakeholders. It follows the project's CLAUDE.md standards for weekly reporting.

## When to Use

Use this skill when:
- User asks to create or generate a weekly QA report
- User mentions "ì£¼ê°„ ë¦¬í¬íŠ¸", "weekly report", or "QA summary"
- It's Friday afternoon (14:00-16:00) and reporting time
- User provides test execution data and asks for analysis
- User wants to track KPIs (Pass Rate, automation coverage, etc.)
- Sprint/week completion requires documentation

## Instructions

### 1. Data Collection

First, gather all necessary data from the week:

**Test Execution Data**:
- Total test cases executed (Tier 1 + Tier 2 + Tier 3)
- Pass count
- Fail count
- Blocked/Skipped count
- Pass Rate calculation

**Issue Tracking Data**:
- New issues discovered (by priority: P0/P1/P2/P3)
- Issues resolved this week
- Currently open issues
- Average resolution time by priority
- Critical issues (P0) status

**Automation Metrics**:
- Current automation coverage %
- New automated tests added this week
- Automation execution time
- Flaky test count

**Release Information**:
- Release status (Go/No-go)
- Features released
- Features blocked
- Production incidents (if any)

**Team Activity**:
- Hours spent per tier (Tier 1/2/3)
- Team member contributions
- Exploratory testing findings

If data is missing, ask the user:
- What is the test execution summary?
- How many issues were found and resolved?
- What is the current automation coverage?
- Was there a release this week?

### 2. Calculate KPIs

Calculate key performance indicators:

**Pass Rate**:
```
Pass Rate = (Pass Count / Total Executed) Ã— 100%
Target: 95% or higher
```

**Automation Coverage**:
```
Automation Coverage = (Automated Tests / Total Tier 1 Tests) Ã— 100%
Target: 80% (6-month goal)
```

**Issue Resolution Metrics**:
- P0: Average time to resolve (Target: 24 hours)
- P1: Average time to resolve (Target: 3 days)
- P2: Average time to resolve (Target: 7 days)

**Release Health**:
- Go/No-go decision
- Blocking issues count
- Production incident count

### 3. Generate Report

Create the report following this structure:

```markdown
# ì£¼ê°„ QA ë¦¬í¬íŠ¸ - Week [N]

**ë³´ê³  ê¸°ê°„**: YYYY-MM-DD ~ YYYY-MM-DD
**ì‘ì„±ì**: QA í—¤ë“œ
**ì‘ì„±ì¼**: YYYY-MM-DD

---

## ğŸ“Š í•µì‹¬ ì§€í‘œ (Key Metrics)

| Metric | This Week | Last Week | Target | Status |
|--------|-----------|-----------|--------|--------|
| Pass Rate | XX% | XX% | 95% | âœ…/âš ï¸/âŒ |
| Automation Coverage | XX% | XX% | 80% | âœ…/âš ï¸/âŒ |
| Open P0 Issues | X | X | 0 | âœ…/âš ï¸/âŒ |
| Avg P0 Resolution Time | Xh | Xh | 24h | âœ…/âš ï¸/âŒ |

**Status Legend**:
- âœ… ëª©í‘œ ë‹¬ì„± (Green)
- âš ï¸ ê°œì„  í•„ìš” (Yellow)
- âŒ ëª©í‘œ ë¯¸ë‹¬ (Red)

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í˜„í™©

### ì „ì²´ í…ŒìŠ¤íŠ¸ ìš”ì•½
- **Total Executed**: Xê±´
- **Pass**: Xê±´ (XX%)
- **Fail**: Xê±´ (XX%)
- **Blocked/Skipped**: Xê±´ (XX%)

### Tierë³„ ìƒì„¸
| Tier | Executed | Pass | Fail | Pass Rate |
|------|----------|------|------|-----------|
| Tier 1 (íšŒê·€) | X | X | X | XX% |
| Tier 2 (íƒìƒ‰) | X | X | X | XX% |
| Tier 3 (ì‹ ê·œ) | X | X | X | XX% |

---

## ğŸ› ì´ìŠˆ í˜„í™©

### ì‹ ê·œ ì´ìŠˆ
- **P0 (Critical)**: Xê±´
- **P1 (High)**: Xê±´
- **P2 (Medium)**: Xê±´
- **P3 (Low)**: Xê±´
- **Total**: Xê±´

### í•´ê²°ëœ ì´ìŠˆ
- **P0**: Xê±´ (í‰ê·  í•´ê²° ì‹œê°„: Xh)
- **P1**: Xê±´ (í‰ê·  í•´ê²° ì‹œê°„: Xd)
- **P2**: Xê±´ (í‰ê·  í•´ê²° ì‹œê°„: Xd)
- **P3**: Xê±´
- **Total**: Xê±´

### ì˜¤í”ˆ ì´ìŠˆ (í˜„ì¬)
- **P0**: Xê±´ [Blocking]
- **P1**: Xê±´
- **P2**: Xê±´
- **P3**: Xê±´
- **Total**: Xê±´

### ì£¼ìš” ì´ìŠˆ ìƒì„¸

#### P0 ì´ìŠˆ (ìˆëŠ” ê²½ìš°ë§Œ)
1. **[ISSUE-XXX] ì´ìŠˆ ì œëª©**
   - Status: In Progress / Resolved
   - Assigned: ë‹´ë‹¹ì
   - Found: YYYY-MM-DD
   - Impact: ìƒì„¸ ì˜í–¥ë„

---

## ğŸ¤– ìë™í™” í˜„í™©

### ì»¤ë²„ë¦¬ì§€ ì§„í–‰
- **Current Coverage**: XX% (XX/XX tests)
- **New This Week**: +X tests automated
- **Target**: 80% (by YYYY-MM)
- **Progress**: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘] XX%

### ìë™í™” ì‹¤í–‰ ê²°ê³¼
- **Total Automated Tests**: Xê±´
- **Execution Time**: Xë¶„
- **Pass Rate**: XX%
- **Flaky Tests**: Xê±´ (ìš”ê°œì„ )

### ì´ë²ˆ ì£¼ ìë™í™” ì¶”ê°€
1. TC-XXX: í…ŒìŠ¤íŠ¸ëª… (Tier X â†’ Tier 1)
2. TC-XXX: í…ŒìŠ¤íŠ¸ëª… (Tier X â†’ Tier 1)

---

## ğŸš€ ë¦´ë¦¬ì¦ˆ í˜„í™©

### ë¦´ë¦¬ì¦ˆ ê²°ì •
- **Status**: âœ… Go / âŒ No-go
- **Date**: YYYY-MM-DD
- **Version**: vX.X.X

### ë¦´ë¦¬ì¦ˆëœ ê¸°ëŠ¥
1. **[Feature Name]**
   - Tier 3 í…ŒìŠ¤íŠ¸: Xê±´ (Pass Rate: XX%)
   - ì£¼ìš” ê²€ì¦ í•­ëª©: [í•­ëª© ë‚˜ì—´]
   - Status: âœ… Released / â¸ï¸ Blocked

### ë¸”ë¡œí‚¹ ì´ìŠˆ
- P0 ì´ìŠˆë¡œ ì¸í•œ ë¦´ë¦¬ì¦ˆ ì§€ì—°/ë³´ë¥˜ ë‚´ì—­

### í”„ë¡œë•ì…˜ í˜„í™©
- Production Incidents: Xê±´
- Rollback: XíšŒ
- Hotfix: Xê±´

---

## ğŸ‘¥ íŒ€ í™œë™

### ì‹œê°„ íˆ¬ì… í˜„í™©
| ì—­í•  | ê³„íš | ì‹¤ì œ | Tier 1 | Tier 2 | Tier 3 | ê¸°íƒ€ |
|------|------|------|--------|--------|--------|------|
| QA í—¤ë“œ | 15h | Xh | Xh | Xh | Xh | Xh |
| í´ë¼ìš°ë“œ | 5h | Xh | Xh | Xh | Xh | Xh |
| ë””ìì´ë„ˆ | 5h | Xh | Xh | Xh | Xh | Xh |
| ê°œë°œì | 3h | Xh | Xh | Xh | Xh | Xh |

### Tier 2 íƒìƒ‰ì  í…ŒìŠ¤íŠ¸
- **ë‹´ë‹¹ì**: [ì´ë¦„]
- **ì‹œë‚˜ë¦¬ì˜¤**: [íƒìƒ‰í•œ ì‹œë‚˜ë¦¬ì˜¤]
- **ë°œê²¬ ì‚¬í•­**:
  - ë²„ê·¸: Xê±´
  - UX ê°œì„ ì : Xê±´
  - ì¸ì‚¬ì´íŠ¸: [ì£¼ìš” ì¸ì‚¬ì´íŠ¸]

---

## ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸

### âœ… ì˜ëœ ì  (Wins)
1. [ì„±ê³¼ 1]
2. [ì„±ê³¼ 2]
3. [ì„±ê³¼ 3]

### âš ï¸ ê°œì„  í•„ìš” (Areas for Improvement)
1. [ê°œì„ ì  1]
2. [ê°œì„ ì  2]
3. [ê°œì„ ì  3]

### ğŸ¯ ì•¡ì…˜ ì•„ì´í…œ (Action Items)
1. **[Action Item 1]**
   - ë‹´ë‹¹: [ë‹´ë‹¹ì]
   - ê¸°í•œ: YYYY-MM-DD
   - Priority: P0/P1/P2

2. **[Action Item 2]**
   - ë‹´ë‹¹: [ë‹´ë‹¹ì]
   - ê¸°í•œ: YYYY-MM-DD
   - Priority: P0/P1/P2

---

## ğŸ“… ë‹¤ìŒ ì£¼ ê³„íš

### Tier 3 ì‹ ê·œ ê¸°ëŠ¥
1. **[Feature Name]**
   - ì¼ì •: YYYY-MM-DD ~ YYYY-MM-DD
   - ì˜ˆìƒ ì¼€ì´ìŠ¤: Xê±´
   - ë‹´ë‹¹: [ë‹´ë‹¹ì]

### ìë™í™” ëª©í‘œ
- Tier 1 ì´ê´€: Xê±´
- Coverage ëª©í‘œ: XX% â†’ YY%

### íŠ¹ì´ì‚¬í•­
- [ë‹¤ìŒ ì£¼ íŠ¹ë³„ ì´ë²¤íŠ¸/ë§ˆì¼ìŠ¤í†¤]

---

## ğŸ“ ì°¸ê³  ë§í¬

- [Notion - í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ í†µí•© DB](ë§í¬)
- [Notion - ì´ìŠˆ íŠ¸ë˜í‚¹ DB](ë§í¬)
- [CI/CD - ìë™í™” ëŒ€ì‹œë³´ë“œ](ë§í¬)
- [í”„ë¡œë•ì…˜ ëª¨ë‹ˆí„°ë§](ë§í¬)

---

**ë‹¤ìŒ ë¦¬í¬íŠ¸**: YYYY-MM-DD (ê¸ˆìš”ì¼)
```

### 4. Status Indicators

Use clear status indicators:

**âœ… Green (ëª©í‘œ ë‹¬ì„±)**:
- Pass Rate â‰¥ 95%
- P0 issues = 0
- Automation coverage on track
- All releases successful

**âš ï¸ Yellow (ê°œì„  í•„ìš”)**:
- Pass Rate 90-94%
- P0 issues resolved but took > 24h
- Automation coverage slightly behind
- Minor production incidents

**âŒ Red (ëª©í‘œ ë¯¸ë‹¬)**:
- Pass Rate < 90%
- Open P0 issues exist
- Release blocked
- Major production incidents

### 5. Insights and Recommendations

Provide actionable insights:

**Trend Analysis**:
- Compare current week vs last week
- Identify improving/degrading metrics
- Highlight patterns (e.g., recurring issues)

**Risk Assessment**:
- Flag concerning trends (e.g., declining Pass Rate)
- Identify bottlenecks (e.g., slow P0 resolution)
- Predict future issues (e.g., coverage falling behind)

**Recommendations**:
- Specific, actionable suggestions
- Prioritized by impact
- Assigned to specific roles

## Guidelines

**DO**:
- Base all data on actual measurements
- Show week-over-week trends
- Highlight both wins and areas for improvement
- Include specific action items with owners
- Use visual indicators (âœ…âš ï¸âŒ) for quick scanning
- Link to relevant Notion pages for details
- Keep executive summary concise
- Provide context for metrics (why they matter)

**DON'T**:
- Make up data - ask if information is missing
- Only report positive news (be transparent)
- Use vague language ("some issues", "a few tests")
- Skip trend analysis
- Forget to assign action items
- Ignore automation coverage tracking
- Overlook team time investment

## Examples

### Example 1: Successful Week

**Input**:
```
ê¸°ê°„: 2024-11-11 ~ 2024-11-15
í…ŒìŠ¤íŠ¸:
- Tier 1: 50ê±´ (Pass 49, Fail 1) = 98%
- Tier 2: 8ì‹œë‚˜ë¦¬ì˜¤ (ë²„ê·¸ 2ê±´ ë°œê²¬)
- Tier 3: 35ê±´ (Pass 33, Fail 2) = 94.3%
ì´ìŠˆ:
- ì‹ ê·œ: P0(0), P1(3), P2(5) = 8ê±´
- í•´ê²°: P0(0), P1(4), P2(3) = 7ê±´
- ì˜¤í”ˆ: P0(0), P1(2), P2(8) = 10ê±´
ìë™í™”:
- í˜„ì¬: 38/50 = 76%
- ì‹ ê·œ ì¶”ê°€: 3ê±´
ë¦´ë¦¬ì¦ˆ: Go (v2.3.0, 11/15)
```

**Output**: [Full report as shown in template with all data filled in, showing âœ… for Pass Rate, âš ï¸ for automation coverage, insights highlighting successful release and steady automation progress]

### Example 2: Challenging Week

**Input**:
```
ê¸°ê°„: 2024-11-18 ~ 2024-11-22
í…ŒìŠ¤íŠ¸:
- Tier 1: 50ê±´ (Pass 45, Fail 5) = 90%
- Tier 3: 28ê±´ (Pass 23, Fail 5) = 82.1%
ì´ìŠˆ:
- ì‹ ê·œ: P0(1), P1(5), P2(4) = 10ê±´
- í•´ê²°: P0(1/48ì‹œê°„), P1(2), P2(1) = 4ê±´
- ì˜¤í”ˆ: P0(0), P1(5), P2(11) = 16ê±´
ìë™í™”: 38/50 = 76% (ë³€í™” ì—†ìŒ)
ë¦´ë¦¬ì¦ˆ: No-go (P0 ì´ìŠˆë¡œ ì¸í•œ ì§€ì—°)
```

**Output**: [Full report showing âŒ for Pass Rate, âŒ for P0 resolution time, detailed P0 issue section, action items for addressing quality concerns, recommendation to focus on stability before new features]

## Best Practices

### 1. Data Accuracy
- Verify all numbers before reporting
- Cross-check with Notion databases
- Ensure calculations are correct (Pass Rate, etc.)

### 2. Storytelling
- Start with executive summary (1-2 sentences)
- Use data to tell the week's story
- Connect metrics to business impact

### 3. Actionable Insights
- Don't just report numbers, explain what they mean
- Every âŒ or âš ï¸ should have a corresponding action item
- Prioritize recommendations by impact

### 4. Consistent Format
- Use the same template every week for comparability
- Maintain consistent naming conventions
- Keep report length manageable (2-3 pages)

### 5. Stakeholder Focus
- QA í—¤ë“œ: All details
- ê°œë°œì: Issues and action items
- ê²½ì˜ì§„: Executive summary and key metrics
- í´ë¼ìš°ë“œ: Automation and infrastructure

## Integration with CLAUDE.md

Always follow standards from `/Users/atad/Desktop/QA/CLAUDE.md`:

**KPI Targets**:
- Pass Rate: 95% or higher
- Automation Coverage: 80% (6-month goal)
- P0 Resolution Time: 24 hours
- P1 Resolution Time: 3 days
- P2 Resolution Time: 7 days

**Workflow**:
- Reports generated every Friday afternoon (14:00-16:00)
- Part of weekly retrospective
- Shared with entire team
- Archived in Notion

**3-Tier System**:
- Track each tier separately
- Show Tier 3 â†’ Tier 1 migration progress
- Highlight Tier 2 exploratory findings

## Output Format

Provide the report in two formats:

### 1. Markdown Format (for Notion)
- Full structured report as shown in template
- Ready to paste into Notion
- Includes all sections and tables

### 2. Executive Summary (for Slack/Email)
```
ğŸ“Š ì£¼ê°„ QA ë¦¬í¬íŠ¸ - Week N (MM/DD ~ MM/DD)

**Status**: âœ… Good / âš ï¸ Caution / âŒ Critical

**Key Metrics**:
â€¢ Pass Rate: XX% (Target: 95%)
â€¢ Automation: XX% (Target: 80%)
â€¢ Open P0: Xê±´
â€¢ Release: Go / No-go

**Highlights**:
âœ… [Major win]
âš ï¸ [Area needing attention]

**Action Required**:
ğŸ¯ [Critical action item]

Full report: [Notion link]
```

## Error Handling

If data is incomplete:

1. **List what's missing**:
   ```
   ë‹¤ìŒ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤:
   - [ ] í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ê²°ê³¼ (Tier 1, 2, 3)
   - [ ] ì´ìŠˆ í˜„í™© (ì‹ ê·œ/í•´ê²°/ì˜¤í”ˆ)
   - [ ] ìë™í™” ì»¤ë²„ë¦¬ì§€
   - [ ] ë¦´ë¦¬ì¦ˆ ìƒíƒœ
   ```

2. **Provide what you can**:
   - Generate report with available data
   - Mark missing sections as "ë°ì´í„° ì—†ìŒ"
   - Estimate based on trends (with disclaimer)

3. **Ask specific questions**:
   - "Tier 3 í…ŒìŠ¤íŠ¸ëŠ” ëª‡ ê±´ ì‹¤í–‰í–ˆë‚˜ìš”?"
   - "P0 ì´ìŠˆëŠ” ëª‡ ê±´ ë°œê²¬ë˜ì—ˆë‚˜ìš”?"
   - "ì´ë²ˆ ì£¼ ë¦´ë¦¬ì¦ˆ ì—¬ë¶€ëŠ” ì–´ë–»ê²Œ ë˜ì—ˆë‚˜ìš”?"

## Notes

- Reports should be objective and data-driven
- Celebrate wins but don't hide problems
- Trends are more important than single-week metrics
- Action items must have owners and deadlines
- Review previous week's action items for follow-up
- Keep report concise but comprehensive
- Archive all weekly reports in Notion for historical tracking
